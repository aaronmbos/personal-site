---
id: 67
slug: lean-into-ai
title: "Is it Time to Lean into AI"
description: "As developers we are constantly exposed to new tools and technologies, but the most recent wave of AI advancements feels different. In this post, I'm going to share my thoughts on whether or not the hype around generative AI is real."
publishedAt: 2023-04-15T22:00:00.000Z
updatedAt: 2023-04-15T22:00:00.000Z
metadata: dev,thoughts,ai
---

Artificial intelligence has been around for a long time both in theory and in practicality. Alan Turing developed the Turing Test as early as 1950 and since then there's been gradual advancements in the space of artificial intelligence and machine learning. As the technology has evolved we've found ways to integrate it into our lives through games like chess, search engines, recommendation systems, autonomous vehicles, and much more. So if all of this technology has been in place for so long what makes the recent advancements in **generative AI** and around OpenAI's ChatGPT different? Is there any substance behind all of the hype that it has received or is the hype not real? Honestly, I don't have answers to these questions, but I do have some thoughts that I'd like to get out of my head.

The recent advancements in generative AI, that is artificial intelligence that is capable of creating content, feel different to me. For the first time that I can remember we are able to ask machines to create content like code, stories, images, videos, music, etc. from nothing. At least it seems like it is creating it from nothing. Its my understanding that the underlying language models have been trained on so much data from the web that they're able to translate just about any request into a response that feels unique.

In the past year we've seen the introduction of ChatGPT and GitHub Copilot, which both seem to be revolutionary tools in their own right. OpenAI's ChatGPT is built with massive language models that are able to provide "human-like" responses to text prompts. The free version of ChatGPT is using GPT-3.5 which is impressive, but is limited in the amount of tokens it can store which limits its effectiveness. The latest release of ChatGPT with GPT-4 appears to improve upon the shortcomings of its predecessor, which makes it potentially more useful. I haven't had a chance experiment with ChatGPT using GPT-4 yet since it is behind their subscription, but from a software engineer's perspective I think this [video](https://www.youtube.com/watch?v=N4sDzidCudQ) by Nick Chapsas does a great job of demonstrating its power.

With each release and advancement in this space the question that keeps coming up for knowledge workers (like software engineers) is _"Should we be worried about our jobs?"_. I think that everyone has their own opinion to this, but my take is that the time will eventually come when software engineers, at least as we view them today, will no longer be needed. However, I don't think that time will come for a long time. I think in the meantime, knowledge workers will find it beneficial to begin adopting the tools provided by these advancements and use them to increase their productivity. By doing so we make ourselves more valuable to the companies that we work, but also potentially continue to push the needle on the level of abstractions that we operate at. Currently most software engineers spend a lot of time writing and reading code that gets packaged and deployed for use by other developers, servers, or end users. What if the tools provide an opportunity to begin composing systems and applicatoins at a layer higher than the code? I'm not sure if this is possible, but I think its where things could be headed.

I'll be honest, I've taken my time on joing the hype train that is gaining steam around AI-based tools, but there comes a time when the hype doesn't feel like hype anymore.
